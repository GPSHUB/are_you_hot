{
 "cells": [
  {
   "source": [
    "# Hot Project Machine Learning Model\n",
    "\n",
    "###  This model reflects manual process for comming up witn an effective model for a classificaiton Project\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies needed to build our model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3 \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, plot_roc_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm"
   ]
  },
  {
   "source": [
    "## EVALUATE FUNCTION\n",
    "\n",
    "Since we will be trying lots of different models, we built a single function that will evaluate all our models and provide a standardized reporting format.\n",
    "\n",
    "This will allow us to easily pick out the best model we want to move forward with.\n",
    "\n",
    "This function takes in a model ( pipeline ) and our train test split data. From there it simply performes predictions and generates results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Evaluate a pipeline on training and test datasets\n",
    "    '''    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_train_hat = pipeline.predict(X_train)\n",
    "    y_test_hat = pipeline.predict(X_test)\n",
    "    train_f1 = f1_score(y_train_hat, y_train)\n",
    "    train_acc = accuracy_score(y_train_hat, y_train)\n",
    "    test_f1 = f1_score(y_test_hat, y_test)\n",
    "    test_acc = accuracy_score(y_test_hat, y_test)\n",
    "\n",
    "    print(f\"========== Predictor: {type(pipeline).__name__} ==========\")\n",
    "    print(f\"Training result: f1: {train_f1:.3f}, acc: {train_acc:.3f}\")\n",
    "    print(f\"Test result: f1: {test_f1:.3f}, acc: {test_acc:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "source": [
    "## DATA\n",
    "In this case we are reading in top 200 hot and not hot people data.  With this data we are trying to predict if an individual is hot or not based on specific features.\n",
    "\n",
    "#### The features are:\n",
    "- Sex  ->   Male or Female.\n",
    "- Age -> How old is an indiviual.\n",
    "- Eye Color -> Variation of eyes colors.\n",
    "- Hair Color -> Different hair colors effect looks.\n",
    "- Distinctive Features -> Mainly related to how an individual look like.\n",
    "- Height -> How tall are they.\n",
    "- Weight -> Body mass effect looks.\n",
    "- Zodiac Sign -> Is your star lucky.\n",
    "- Tattoo Body Art -> Do they have any inks in their body."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              name     sex         dob  birth_year eye_color hair_color  \\\n",
       "0   Angelina Jolie  Female  06/04/1975        1975      Gray     Blonde   \n",
       "1      Johnny Depp    Male  06/09/1963        1963     Brown      Brown   \n",
       "2  Charlize Theron  Female  08/07/1975        1975     Green      Brown   \n",
       "3        Brad Pitt    Male  12/18/1963        1963      Blue     Blonde   \n",
       "4      Amber Heard  Female  04/22/1986        1986      Blue     Blonde   \n",
       "5       Jared Leto    Male  12/26/1971        1971      Blue      Brown   \n",
       "6  Natalie Portman  Female  06/09/1981        1981     Hazel      Brown   \n",
       "7   Channing Tatum    Male  04/26/1980        1980     Green      Brown   \n",
       "8       Mila Kunis  Female  08/14/1983        1983     Green      Brown   \n",
       "9  Chris Hemsworth    Male  08/11/1983        1983      Blue     Blonde   \n",
       "\n",
       "  distinctive_features  height(ft)  weight(lbs)  zodiac_sign tattoo_body_art  \\\n",
       "0                 Lips        5.50        119.0       Gemini             Yes   \n",
       "1           Cheekbones        5.83        171.0       Gemini             Yes   \n",
       "2           Attractive        5.75        121.0          Leo             Yes   \n",
       "3                  Jaw        5.91        172.0  Sagittarius             Yes   \n",
       "4                 Body        5.58        137.0       Taurus             Yes   \n",
       "5                 Eyes        5.75        152.0    Capricorn             Yes   \n",
       "6                Moles        5.25        110.0       Gemini              No   \n",
       "7                 Eyes        6.08        196.0       Taurus             Yes   \n",
       "8                 Body        5.33        115.0          Leo              No   \n",
       "9                Voice        6.25        201.0          Leo             Yes   \n",
       "\n",
       "   hot_test  ratio(wt/ht)  age  \n",
       "0         0         21.64   45  \n",
       "1         0         29.33   57  \n",
       "2         0         21.04   45  \n",
       "3         0         29.10   57  \n",
       "4         0         24.55   34  \n",
       "5         0         26.43   49  \n",
       "6         0         20.95   39  \n",
       "7         0         32.24   40  \n",
       "8         0         21.58   37  \n",
       "9         0         32.16   37  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>sex</th>\n      <th>dob</th>\n      <th>birth_year</th>\n      <th>eye_color</th>\n      <th>hair_color</th>\n      <th>distinctive_features</th>\n      <th>height(ft)</th>\n      <th>weight(lbs)</th>\n      <th>zodiac_sign</th>\n      <th>tattoo_body_art</th>\n      <th>hot_test</th>\n      <th>ratio(wt/ht)</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Angelina Jolie</td>\n      <td>Female</td>\n      <td>06/04/1975</td>\n      <td>1975</td>\n      <td>Gray</td>\n      <td>Blonde</td>\n      <td>Lips</td>\n      <td>5.50</td>\n      <td>119.0</td>\n      <td>Gemini</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>21.64</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Johnny Depp</td>\n      <td>Male</td>\n      <td>06/09/1963</td>\n      <td>1963</td>\n      <td>Brown</td>\n      <td>Brown</td>\n      <td>Cheekbones</td>\n      <td>5.83</td>\n      <td>171.0</td>\n      <td>Gemini</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>29.33</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Charlize Theron</td>\n      <td>Female</td>\n      <td>08/07/1975</td>\n      <td>1975</td>\n      <td>Green</td>\n      <td>Brown</td>\n      <td>Attractive</td>\n      <td>5.75</td>\n      <td>121.0</td>\n      <td>Leo</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>21.04</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Brad Pitt</td>\n      <td>Male</td>\n      <td>12/18/1963</td>\n      <td>1963</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Jaw</td>\n      <td>5.91</td>\n      <td>172.0</td>\n      <td>Sagittarius</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>29.10</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Amber Heard</td>\n      <td>Female</td>\n      <td>04/22/1986</td>\n      <td>1986</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Body</td>\n      <td>5.58</td>\n      <td>137.0</td>\n      <td>Taurus</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>24.55</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jared Leto</td>\n      <td>Male</td>\n      <td>12/26/1971</td>\n      <td>1971</td>\n      <td>Blue</td>\n      <td>Brown</td>\n      <td>Eyes</td>\n      <td>5.75</td>\n      <td>152.0</td>\n      <td>Capricorn</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>26.43</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Natalie Portman</td>\n      <td>Female</td>\n      <td>06/09/1981</td>\n      <td>1981</td>\n      <td>Hazel</td>\n      <td>Brown</td>\n      <td>Moles</td>\n      <td>5.25</td>\n      <td>110.0</td>\n      <td>Gemini</td>\n      <td>No</td>\n      <td>0</td>\n      <td>20.95</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Channing Tatum</td>\n      <td>Male</td>\n      <td>04/26/1980</td>\n      <td>1980</td>\n      <td>Green</td>\n      <td>Brown</td>\n      <td>Eyes</td>\n      <td>6.08</td>\n      <td>196.0</td>\n      <td>Taurus</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>32.24</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Mila Kunis</td>\n      <td>Female</td>\n      <td>08/14/1983</td>\n      <td>1983</td>\n      <td>Green</td>\n      <td>Brown</td>\n      <td>Body</td>\n      <td>5.33</td>\n      <td>115.0</td>\n      <td>Leo</td>\n      <td>No</td>\n      <td>0</td>\n      <td>21.58</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Chris Hemsworth</td>\n      <td>Male</td>\n      <td>08/11/1983</td>\n      <td>1983</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Voice</td>\n      <td>6.25</td>\n      <td>201.0</td>\n      <td>Leo</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>32.16</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# load dataset from sqlite dataBase. Creat an engine and then use pandas to read and convert the sql table into dataframe\n",
    "\n",
    "engine = create_engine('sqlite:///../dataBase/Are_You_Hot.db')\n",
    "hot_df = pd.read_sql('select * from hot', engine)\n",
    "hot_df.head(10)"
   ]
  },
  {
   "source": [
    "## DataFrame cleanup "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        sex eye_color distinctive_features  zodiac_sign  hot_test  \\\n",
       "196    Male     Brown                Smile  Sagittarius         1   \n",
       "197    Male     Black                 Face       Cancer         1   \n",
       "198    Male     Brown                 Hair  Sagittarius         1   \n",
       "199  Female     Black                Smile       Cancer         1   \n",
       "200    Male      Blue                 Hair       Cancer         1   \n",
       "\n",
       "     ratio(wt/ht)  age  \n",
       "196         36.38   68  \n",
       "197         32.48   57  \n",
       "198         30.00   55  \n",
       "199         57.09   37  \n",
       "200         27.65   38  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>eye_color</th>\n      <th>distinctive_features</th>\n      <th>zodiac_sign</th>\n      <th>hot_test</th>\n      <th>ratio(wt/ht)</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>196</th>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>Smile</td>\n      <td>Sagittarius</td>\n      <td>1</td>\n      <td>36.38</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Male</td>\n      <td>Black</td>\n      <td>Face</td>\n      <td>Cancer</td>\n      <td>1</td>\n      <td>32.48</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>Hair</td>\n      <td>Sagittarius</td>\n      <td>1</td>\n      <td>30.00</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Female</td>\n      <td>Black</td>\n      <td>Smile</td>\n      <td>Cancer</td>\n      <td>1</td>\n      <td>57.09</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>Male</td>\n      <td>Blue</td>\n      <td>Hair</td>\n      <td>Cancer</td>\n      <td>1</td>\n      <td>27.65</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Data clean up and droping columns we are not going to use to train our model.\n",
    "\n",
    "clean_df = hot_df.drop(['name', 'dob', 'birth_year', 'height(ft)', 'weight(lbs)', 'hair_color', 'tattoo_body_art'], axis=1)\n",
    "clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Blue     91\n",
       "Brown    55\n",
       "Green    29\n",
       "Hazel    19\n",
       "Black     5\n",
       "Gray      2\n",
       "Name: Eye Color, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "y = hot_df['Eye Color'].value_counts()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      sex eye_color distinctive_features  zodiac_sign  hot_test  ratio(wt/ht)  \\\n",
       "0  Female      Gray                 Lips       Others         0         21.64   \n",
       "1    Male     Brown           Cheekbones       Others         0         29.33   \n",
       "2  Female     Green           Attractive          Leo         0         21.04   \n",
       "3    Male      Blue                Other  Sagittarius         0         29.10   \n",
       "4  Female      Blue                 Body       Taurus         0         24.55   \n",
       "\n",
       "   age  \n",
       "0   45  \n",
       "1   57  \n",
       "2   45  \n",
       "3   57  \n",
       "4   34  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>eye_color</th>\n      <th>distinctive_features</th>\n      <th>zodiac_sign</th>\n      <th>hot_test</th>\n      <th>ratio(wt/ht)</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>Gray</td>\n      <td>Lips</td>\n      <td>Others</td>\n      <td>0</td>\n      <td>21.64</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>Cheekbones</td>\n      <td>Others</td>\n      <td>0</td>\n      <td>29.33</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>Green</td>\n      <td>Attractive</td>\n      <td>Leo</td>\n      <td>0</td>\n      <td>21.04</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>Blue</td>\n      <td>Other</td>\n      <td>Sagittarius</td>\n      <td>0</td>\n      <td>29.10</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>Blue</td>\n      <td>Body</td>\n      <td>Taurus</td>\n      <td>0</td>\n      <td>24.55</td>\n      <td>34</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clean_df['distinctive_features'] = clean_df['distinctive_features'].replace({'Bald': 'Other', 'Goatee': 'Other', 'Moles': 'Other', 'Skin': 'Other', 'Height': 'Other', 'Forehead': 'Other', 'Style': 'Other', 'Cheeks': 'Other', 'Jaw': 'Other', 'Legs': 'Other', 'Stubble': 'Other'})\n",
    "# clean_df['Eye Color'] = clean_df['Eye Color'].replace({'Black': 'Others', 'Gray': 'Others'})\n",
    "clean_df['zodiac_sign'] = clean_df['zodiac_sign'].replace({'Pisces': 'Others', 'Aries': 'Others', 'Virgo': 'Others', 'Libra': 'Others', 'Aquarius': 'Others', 'Gemini': 'Others'})\n",
    "# , 'Green and Blue': 'Others'\n",
    "model_df = clean_df\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 201 entries, 0 to 200\nData columns (total 32 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   sex_Male                         201 non-null    uint8  \n 1   eye_color_Blue                   201 non-null    uint8  \n 2   eye_color_Brown                  201 non-null    uint8  \n 3   eye_color_Gray                   201 non-null    uint8  \n 4   eye_color_Green                  201 non-null    uint8  \n 5   eye_color_Hazel                  201 non-null    uint8  \n 6   distinctive_features_Body        201 non-null    uint8  \n 7   distinctive_features_Cheekbones  201 non-null    uint8  \n 8   distinctive_features_Chin        201 non-null    uint8  \n 9   distinctive_features_Ears        201 non-null    uint8  \n 10  distinctive_features_Eyebrows    201 non-null    uint8  \n 11  distinctive_features_Eyes        201 non-null    uint8  \n 12  distinctive_features_Face        201 non-null    uint8  \n 13  distinctive_features_Hair        201 non-null    uint8  \n 14  distinctive_features_Jawline     201 non-null    uint8  \n 15  distinctive_features_Lips        201 non-null    uint8  \n 16  distinctive_features_Muscular    201 non-null    uint8  \n 17  distinctive_features_Nose        201 non-null    uint8  \n 18  distinctive_features_Other       201 non-null    uint8  \n 19  distinctive_features_Smile       201 non-null    uint8  \n 20  distinctive_features_Teeth       201 non-null    uint8  \n 21  distinctive_features_Voice       201 non-null    uint8  \n 22  zodiac_sign_Cancer               201 non-null    uint8  \n 23  zodiac_sign_Capricorn            201 non-null    uint8  \n 24  zodiac_sign_Leo                  201 non-null    uint8  \n 25  zodiac_sign_Others               201 non-null    uint8  \n 26  zodiac_sign_Sagittarius          201 non-null    uint8  \n 27  zodiac_sign_Scorpio              201 non-null    uint8  \n 28  zodiac_sign_Taurus               201 non-null    uint8  \n 29  hot_test                         201 non-null    int64  \n 30  ratio(wt/ht)                     201 non-null    float64\n 31  age                              201 non-null    int64  \ndtypes: float64(1), int64(2), uint8(29)\nmemory usage: 10.5 KB\n"
     ]
    }
   ],
   "source": [
    "# We need to convert any string/object column (categorical variables) to integer for training our model\n",
    "# We use pandas get_dummies to create OneHotEncoder variables. \n",
    "\n",
    "cat_col = model_df.select_dtypes(include=['object']).columns\n",
    "dummies = pd.get_dummies(model_df[cat_col],drop_first=True)\n",
    "without_dummies = model_df.drop(cat_col,axis=1)\n",
    "model_data = pd.concat([dummies,without_dummies],axis=1)\n",
    "model_data.info()"
   ]
  },
  {
   "source": [
    "## Extract Features from Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sex_Male                           0\n",
       "eye_color_Blue                     0\n",
       "eye_color_Brown                    0\n",
       "eye_color_Gray                     0\n",
       "eye_color_Green                    0\n",
       "eye_color_Hazel                    0\n",
       "distinctive_features_Body          0\n",
       "distinctive_features_Cheekbones    0\n",
       "distinctive_features_Chin          0\n",
       "distinctive_features_Ears          0\n",
       "distinctive_features_Eyebrows      0\n",
       "distinctive_features_Eyes          0\n",
       "distinctive_features_Face          0\n",
       "distinctive_features_Hair          0\n",
       "distinctive_features_Jawline       0\n",
       "distinctive_features_Lips          0\n",
       "distinctive_features_Muscular      0\n",
       "distinctive_features_Nose          0\n",
       "distinctive_features_Other         0\n",
       "distinctive_features_Smile         0\n",
       "distinctive_features_Teeth         0\n",
       "distinctive_features_Voice         0\n",
       "zodiac_sign_Cancer                 0\n",
       "zodiac_sign_Capricorn              0\n",
       "zodiac_sign_Leo                    0\n",
       "zodiac_sign_Others                 0\n",
       "zodiac_sign_Sagittarius            0\n",
       "zodiac_sign_Scorpio                0\n",
       "zodiac_sign_Taurus                 0\n",
       "hot_test                           0\n",
       "ratio(wt/ht)                       0\n",
       "age                                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# make sure there is no nan\n",
    "# if there is nan, we need to deal with it, either by imputing or discarding\n",
    "model_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "The stratify argument is used to make sure the train test split data has similar populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our X and y values for model training and test\n",
    "# , 'Distinctive Features_Bald'\n",
    "X = model_data.drop('hot_test', axis=1)\n",
    "y = hot_df['hot_test'].values.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick A Model For A Base Point To Evaluate Other Models Against\n",
    "\n",
    "In this case we are choosing Logistric Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========== Predictor: Pipeline ==========\nTraining result: f1: 0.820, acc: 0.819\nTest result: f1: 0.650, acc: 0.659\n\n"
     ]
    }
   ],
   "source": [
    "# Do LogisticRegression first to establish a baseline performance\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()), # scale first before feeding data into lgr\n",
    "    ('lgr', LogisticRegression()),\n",
    "])\n",
    "evaluate(pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "source": [
    "## Try A Few More Models..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "========== Predictor: XGBClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.727, acc: 0.707\n",
      "\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.883, acc: 0.887\n",
      "Test result: f1: 0.744, acc: 0.732\n",
      "\n",
      "========== Predictor: RandomForestClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.773, acc: 0.756\n",
      "\n",
      "========== Predictor: DecisionTreeClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.595, acc: 0.634\n",
      "\n",
      "========== Predictor: GradientBoostingClassifier ==========\n",
      "Training result: f1: 0.975, acc: 0.975\n",
      "Test result: f1: 0.732, acc: 0.732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try other predictors\n",
    "\n",
    "evaluate(XGBClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(LGBMClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)\n",
    "evaluate(GradientBoostingClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "gbc_disp = plot_roc_curve(gbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/gbc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state=42)\n",
    "xgbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "xgbc_disp = plot_roc_curve(xgbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/xgbc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc = LGBMClassifier(random_state=42)\n",
    "lgbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "lgbc_disp = plot_roc_curve(lgbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/lgbc_ROC2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "dtc_disp = plot_roc_curve(dtc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/dtc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "dtc_disp.plot(ax=ax, alpha=0.8)\n",
    "lgbc_disp.plot(ax=ax, alpha=0.8)\n",
    "xgbc_disp.plot(ax=ax, alpha=0.8)\n",
    "gbc_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/rfc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Let's Pick a Final Model To Move Forward With\n",
    "\n",
    "From the above evaluations, it looks like LGBMClassifier is a very promising candidate\n",
    "\n",
    "We will then hypertune the classifier model to come up with the best model we can."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Create Our Tuning Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV on LGBM\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 300, 400],\n",
    "    'max_depth': np.arange(5, 20),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.05),\n",
    "    'min_child_weight': np.arange(1, 10),\n",
    "    'colsample_bytree': np.arange(0.2, 1.0, 0.1),\n",
    "    'gamma': [0, 0.001, 0.002, 0.003, 0.004, 0.005, 1e-2],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "#     'learning_rate': [ 0.1],\n",
    "#     'num_leaves': [31],\n",
    "#     'boosting_type' : ['gbdt'],\n",
    "#     'objective' : ['binary']\n",
    "# }\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "\n",
    "#         # 'bagging_fraction': (0.5, 0.8),\n",
    "#         # 'bagging_frequency': (5, 8),\n",
    "#         'n_jobs': [-1]\n",
    "#         'feature_fraction': (0.5, 0.8),\n",
    "#         'max_depth': (10, 13),\n",
    "#         'min_data_in_leaf': (90, 120),\n",
    "#         'num_leaves': (1200, 1550)\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find The Best Model We Can\n",
    "\n",
    "The RandomizedSearchCV function will try all our combinations above and select the most accurate model.  \n",
    "\n",
    "That best model is found in the best_estimator_ property of the RandomizedSerachCV object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.8s\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.774, acc: 0.781\n",
      "Test result: f1: 0.773, acc: 0.756\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Done 485 out of 500 | elapsed:    6.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "predictor = LGBMClassifier()\n",
    "# predictor = XGBClassifier()\n",
    "rs = RandomizedSearchCV(predictor, lgbm_param_grid, cv=5, scoring='f1', n_jobs=-1, n_iter=100, verbose=1)\n",
    "rs.fit(X_train, y_train)\n",
    "evaluate(rs.best_estimator_, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Our Model Further\n",
    "\n",
    "Now we are going to shuffle the data over and over and apply our new model to the results to further determine if we want to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results: 0.69 (0.10) accuracy\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with kfold\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(rs.best_estimator_, X, y, cv=kfold, n_jobs=-1)\n",
    "print(\"Results: %.2f (%.2f) accuracy\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model For Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = list(X.columns)\n",
    "with open(f'model_columns.pickle', 'wb') as f:\n",
    "    pickle.dump(model_columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "with open(f'lgbm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(rs.best_estimator_, f)\n",
    "# with open(f'xgb_model.pickle', 'wb') as f:\n",
    "#     pickle.dump(rs.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm File\n",
    "\n",
    "Make sure the operating system you are NOT using is commented out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Volume in drive C is TI10653400C\n",
      " Volume Serial Number is 24D7-5A9C\n",
      "\n",
      " Directory of c:\\Users\\tahir\\Desktop\\repos\\are_you_hot\\Project_3_Hot_Model\n",
      "\n",
      "12/17/2020  06:01 PM           113,587 lgbm_model.pickle\n",
      "               1 File(s)        113,587 bytes\n",
      "               0 Dir(s)  33,010,659,328 bytes free\n",
      " Volume in drive C is TI10653400C\n",
      " Volume Serial Number is 24D7-5A9C\n",
      "\n",
      " Directory of c:\\Users\\tahir\\Desktop\\repos\\are_you_hot\\Project_3_Hot_Model\n",
      "\n",
      "12/17/2020  06:02 PM               874 model_columns.pickle\n",
      "               1 File(s)            874 bytes\n",
      "               0 Dir(s)  33,010,663,424 bytes free\n"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "# ! dir best_xgb*\n",
    "! dir lgbm_model*\n",
    "# ! dir xgb_model*\n",
    "! dir model_columns*\n",
    "# mac / linux / Unix\n",
    "# ! ls -a best_xgb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('PythonAdv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6de8536eaa4070947253de6ee6fc4b8f7fe35d929fbfb620a9bfbc52619c5b86"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}