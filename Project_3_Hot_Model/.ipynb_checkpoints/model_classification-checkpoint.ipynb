{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot Project Machine Learning Model\n",
    "\n",
    "###  This model reflects manual process for comming up witn an effective model for a classificaiton Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies needed to build our model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3 \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, plot_roc_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE FUNCTION\n",
    "\n",
    "Since we will be trying lots of different models, we built a single function that will evaluate all our models and provide a standardized reporting format.\n",
    "\n",
    "This will allow us to easily pick out the best model we want to move forward with.\n",
    "\n",
    "This function takes in a model ( pipeline ) and our train test split data. From there it simply performes predictions and generates results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Evaluate a pipeline on training and test datasets\n",
    "    '''    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_train_hat = pipeline.predict(X_train)\n",
    "    y_test_hat = pipeline.predict(X_test)\n",
    "    train_f1 = f1_score(y_train_hat, y_train)\n",
    "    train_acc = accuracy_score(y_train_hat, y_train)\n",
    "    test_f1 = f1_score(y_test_hat, y_test)\n",
    "    test_acc = accuracy_score(y_test_hat, y_test)\n",
    "\n",
    "    print(f\"========== Predictor: {type(pipeline).__name__} ==========\")\n",
    "    print(f\"Training result: f1: {train_f1:.3f}, acc: {train_acc:.3f}\")\n",
    "    print(f\"Test result: f1: {test_f1:.3f}, acc: {test_acc:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA\n",
    "In this case we are reading in top 200 hot and not hot people data.  With this data we are trying to predict if an individual is hot or not based on specific features.\n",
    "\n",
    "#### The features are:\n",
    "- Sex  ->   Male or Female.\n",
    "- Age -> How old is an indiviual.\n",
    "- Eye Color -> Variation of eyes colors.\n",
    "- Hair Color -> Different hair colors effect looks.\n",
    "- Distinctive Features -> Mainly related to how an individual look like.\n",
    "- Height -> How tall are they.\n",
    "- Weight -> Body mass effect looks.\n",
    "- Zodiac Sign -> Is your star lucky.\n",
    "- Tattoo Body Art -> Do they have any inks in their body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Eye Color</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Distinctive Features</th>\n",
       "      <th>Height(ft)</th>\n",
       "      <th>Weight(lbs)</th>\n",
       "      <th>Zodiac Sign</th>\n",
       "      <th>Tattoo Body Art</th>\n",
       "      <th>Hot Test</th>\n",
       "      <th>Ht/Wt Ratio</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angelina Jolie</td>\n",
       "      <td>Female</td>\n",
       "      <td>06/04/1975</td>\n",
       "      <td>1975</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Lips</td>\n",
       "      <td>5.50</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>21.64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>Male</td>\n",
       "      <td>06/09/1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Cheekbones</td>\n",
       "      <td>5.83</td>\n",
       "      <td>171.0</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>29.33</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlize Theron</td>\n",
       "      <td>Female</td>\n",
       "      <td>08/07/1975</td>\n",
       "      <td>1975</td>\n",
       "      <td>Green</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Attractive</td>\n",
       "      <td>5.75</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>21.04</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>Male</td>\n",
       "      <td>12/18/1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Jaw</td>\n",
       "      <td>5.91</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amber Heard</td>\n",
       "      <td>Female</td>\n",
       "      <td>04/22/1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Body</td>\n",
       "      <td>5.58</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>24.55</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jared Leto</td>\n",
       "      <td>Male</td>\n",
       "      <td>12/26/1971</td>\n",
       "      <td>1971</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>5.75</td>\n",
       "      <td>152.0</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>26.43</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Natalie Portman</td>\n",
       "      <td>Female</td>\n",
       "      <td>06/09/1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Moles</td>\n",
       "      <td>5.25</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>20.95</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Channing Tatum</td>\n",
       "      <td>Male</td>\n",
       "      <td>04/26/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>Green</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>6.08</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.24</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mila Kunis</td>\n",
       "      <td>Female</td>\n",
       "      <td>08/14/1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>Green and Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Body</td>\n",
       "      <td>5.33</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Leo</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>21.58</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Hemsworth</td>\n",
       "      <td>Male</td>\n",
       "      <td>08/11/1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Voice</td>\n",
       "      <td>6.25</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name     Sex         DOB  Birth Year       Eye Color Hair Color  \\\n",
       "0   Angelina Jolie  Female  06/04/1975        1975            Gray     Blonde   \n",
       "1      Johnny Depp    Male  06/09/1963        1963           Brown      Brown   \n",
       "2  Charlize Theron  Female  08/07/1975        1975           Green      Brown   \n",
       "3        Brad Pitt    Male  12/18/1963        1963            Blue     Blonde   \n",
       "4      Amber Heard  Female  04/22/1986        1986            Blue     Blonde   \n",
       "5       Jared Leto    Male  12/26/1971        1971            Blue      Brown   \n",
       "6  Natalie Portman  Female  06/09/1981        1981           Hazel      Brown   \n",
       "7   Channing Tatum    Male  04/26/1980        1980           Green      Brown   \n",
       "8       Mila Kunis  Female  08/14/1983        1983  Green and Blue      Brown   \n",
       "9  Chris Hemsworth    Male  08/11/1983        1983            Blue     Blonde   \n",
       "\n",
       "  Distinctive Features  Height(ft)  Weight(lbs)  Zodiac Sign Tattoo Body Art  \\\n",
       "0                 Lips        5.50        119.0       Gemini             Yes   \n",
       "1           Cheekbones        5.83        171.0       Gemini             Yes   \n",
       "2           Attractive        5.75        121.0          Leo             Yes   \n",
       "3                  Jaw        5.91        172.0  Sagittarius             Yes   \n",
       "4                 Body        5.58        137.0       Taurus             Yes   \n",
       "5                 Eyes        5.75        152.0    Capricorn             Yes   \n",
       "6                Moles        5.25        110.0       Gemini              No   \n",
       "7                 Eyes        6.08        196.0       Taurus             Yes   \n",
       "8                 Body        5.33        115.0          Leo              No   \n",
       "9                Voice        6.25        201.0          Leo             Yes   \n",
       "\n",
       "   Hot Test  Ht/Wt Ratio  Age  \n",
       "0         0        21.64   45  \n",
       "1         0        29.33   57  \n",
       "2         0        21.04   45  \n",
       "3         0        29.10   57  \n",
       "4         0        24.55   34  \n",
       "5         0        26.43   49  \n",
       "6         0        20.95   39  \n",
       "7         0        32.24   40  \n",
       "8         0        21.58   37  \n",
       "9         0        32.16   37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset from sqlite dataBase. Creat an engine and then use pandas to read and convert the sql table into dataframe\n",
    "\n",
    "engine = create_engine('sqlite:///../dataBase/Are_You_Hot.db')\n",
    "hot_df = pd.read_sql('select * from hot', engine)\n",
    "hot_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Distinctive Features</th>\n",
       "      <th>Tattoo Body Art</th>\n",
       "      <th>Hot Test</th>\n",
       "      <th>Ht/Wt Ratio</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Male</td>\n",
       "      <td>Smile</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>36.38</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Male</td>\n",
       "      <td>Face</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>32.48</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hair</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Female</td>\n",
       "      <td>Smile</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>57.09</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Male</td>\n",
       "      <td>Hair</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>27.65</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Distinctive Features Tattoo Body Art  Hot Test  Ht/Wt Ratio  Age\n",
       "196    Male                Smile              No         1        36.38   68\n",
       "197    Male                 Face              No         1        32.48   57\n",
       "198    Male                 Hair             Yes         1        30.00   55\n",
       "199  Female                Smile              No         1        57.09   37\n",
       "200    Male                 Hair              No         1        27.65   38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data clean up and droping columns we are not going to use to train our model.\n",
    "\n",
    "clean_df = hot_df.drop(['Name', 'DOB', 'Birth Year','Height(ft)', 'Weight(lbs)','Eye Color','Hair Color', 'Zodiac Sign', 'Tattoo Body Art'], axis=1)\n",
    "clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Data columns (total 31 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Sex_Male                         201 non-null    uint8  \n",
      " 1   Distinctive Features_Bald        201 non-null    uint8  \n",
      " 2   Distinctive Features_Body        201 non-null    uint8  \n",
      " 3   Distinctive Features_Cheekbones  201 non-null    uint8  \n",
      " 4   Distinctive Features_Cheeks      201 non-null    uint8  \n",
      " 5   Distinctive Features_Chin        201 non-null    uint8  \n",
      " 6   Distinctive Features_Ears        201 non-null    uint8  \n",
      " 7   Distinctive Features_Eyebrows    201 non-null    uint8  \n",
      " 8   Distinctive Features_Eyes        201 non-null    uint8  \n",
      " 9   Distinctive Features_Face        201 non-null    uint8  \n",
      " 10  Distinctive Features_Forehead    201 non-null    uint8  \n",
      " 11  Distinctive Features_Goatee      201 non-null    uint8  \n",
      " 12  Distinctive Features_Hair        201 non-null    uint8  \n",
      " 13  Distinctive Features_Height      201 non-null    uint8  \n",
      " 14  Distinctive Features_Jaw         201 non-null    uint8  \n",
      " 15  Distinctive Features_Jawline     201 non-null    uint8  \n",
      " 16  Distinctive Features_Legs        201 non-null    uint8  \n",
      " 17  Distinctive Features_Lips        201 non-null    uint8  \n",
      " 18  Distinctive Features_Moles       201 non-null    uint8  \n",
      " 19  Distinctive Features_Muscular    201 non-null    uint8  \n",
      " 20  Distinctive Features_Nose        201 non-null    uint8  \n",
      " 21  Distinctive Features_Skin        201 non-null    uint8  \n",
      " 22  Distinctive Features_Smile       201 non-null    uint8  \n",
      " 23  Distinctive Features_Stubble     201 non-null    uint8  \n",
      " 24  Distinctive Features_Style       201 non-null    uint8  \n",
      " 25  Distinctive Features_Teeth       201 non-null    uint8  \n",
      " 26  Distinctive Features_Voice       201 non-null    uint8  \n",
      " 27  Tattoo Body Art_Yes              201 non-null    uint8  \n",
      " 28  Hot Test                         201 non-null    int64  \n",
      " 29  Ht/Wt Ratio                      201 non-null    float64\n",
      " 30  Age                              201 non-null    int64  \n",
      "dtypes: float64(1), int64(2), uint8(28)\n",
      "memory usage: 10.3 KB\n"
     ]
    }
   ],
   "source": [
    "# We need to convert any string/object column to integer for training our model\n",
    "# We decided to use dummies modeule to do our labeling \n",
    "\n",
    "cat_col = clean_df.select_dtypes(include=['object']).columns\n",
    "dummies = pd.get_dummies(clean_df[cat_col],drop_first=True)\n",
    "without_dummies = clean_df.drop(cat_col,axis=1)\n",
    "clean_data = pd.concat([dummies,without_dummies],axis=1)\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features from Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_Male                           0\n",
       "Distinctive Features_Bald          0\n",
       "Distinctive Features_Body          0\n",
       "Distinctive Features_Cheekbones    0\n",
       "Distinctive Features_Cheeks        0\n",
       "Distinctive Features_Chin          0\n",
       "Distinctive Features_Ears          0\n",
       "Distinctive Features_Eyebrows      0\n",
       "Distinctive Features_Eyes          0\n",
       "Distinctive Features_Face          0\n",
       "Distinctive Features_Forehead      0\n",
       "Distinctive Features_Goatee        0\n",
       "Distinctive Features_Hair          0\n",
       "Distinctive Features_Height        0\n",
       "Distinctive Features_Jaw           0\n",
       "Distinctive Features_Jawline       0\n",
       "Distinctive Features_Legs          0\n",
       "Distinctive Features_Lips          0\n",
       "Distinctive Features_Moles         0\n",
       "Distinctive Features_Muscular      0\n",
       "Distinctive Features_Nose          0\n",
       "Distinctive Features_Skin          0\n",
       "Distinctive Features_Smile         0\n",
       "Distinctive Features_Stubble       0\n",
       "Distinctive Features_Style         0\n",
       "Distinctive Features_Teeth         0\n",
       "Distinctive Features_Voice         0\n",
       "Tattoo Body Art_Yes                0\n",
       "Hot Test                           0\n",
       "Ht/Wt Ratio                        0\n",
       "Age                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there is no nan\n",
    "# if there is nan, we need to deal with it, either by imputing or discarding\n",
    "clean_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "The stratify argument is used to make sure the train test split data has similar populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our X and y values for model training and test\n",
    "\n",
    "X = clean_data.drop('Hot Test', axis=1).values \n",
    "y = hot_df['Hot Test'].values.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick A Model For A Base Point To Evaluate Other Models Against\n",
    "\n",
    "In this case we are choosing Logistric Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Predictor: Pipeline ==========\n",
      "Training result: f1: 0.823, acc: 0.825\n",
      "Test result: f1: 0.700, acc: 0.707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do LogisticRegression first to establish a baseline performance\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()), # scale first before feeding data into lgr\n",
    "    ('lgr', LogisticRegression()),\n",
    "])\n",
    "evaluate(pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try A Few More Models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GPS\\anaconda3.1\\envs\\PythonAdv\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "========== Predictor: XGBClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.667, acc: 0.683\n",
      "\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.857, acc: 0.863\n",
      "Test result: f1: 0.810, acc: 0.805\n",
      "\n",
      "========== Predictor: RandomForestClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.737, acc: 0.756\n",
      "\n",
      "========== Predictor: DecisionTreeClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.703, acc: 0.732\n",
      "\n",
      "========== Predictor: GradientBoostingClassifier ==========\n",
      "Training result: f1: 0.969, acc: 0.969\n",
      "Test result: f1: 0.750, acc: 0.756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try other predictors\n",
    "\n",
    "evaluate(XGBClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(LGBMClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)\n",
    "evaluate(GradientBoostingClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "gbc_disp = plot_roc_curve(gbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/gbc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(random_state=42)\n",
    "xgbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "xgbc_disp = plot_roc_curve(xgbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/xgbc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc = LGBMClassifier(random_state=42)\n",
    "lgbc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "lgbc_disp = plot_roc_curve(lgbc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/lgbc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "dtc_disp = plot_roc_curve(dtc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/dtc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "dtc_disp.plot(ax=ax, alpha=0.8)\n",
    "lgbc_disp.plot(ax=ax, alpha=0.8)\n",
    "xgbc_disp.plot(ax=ax, alpha=0.8)\n",
    "gbc_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.savefig('../Images/rfc_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Pick a Final Model To Move Forward With\n",
    "\n",
    "From the above evaluations, it looks like LGBMClassifier is a very promising candidate\n",
    "\n",
    "We will then hypertune the classifier model to come up with the best model we can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Create Our Tuning Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV on LGBM\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 300, 400],\n",
    "    'max_depth': np.arange(5, 20),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.05),\n",
    "    'min_child_weight': np.arange(1, 10),\n",
    "    'colsample_bytree': np.arange(0.2, 1.0, 0.1),\n",
    "    'gamma': [0, 0.001, 0.002, 0.003, 0.004, 0.005, 1e-2],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "#     'learning_rate': [ 0.1],\n",
    "#     'num_leaves': [31],\n",
    "#     'boosting_type' : ['gbdt'],\n",
    "#     'objective' : ['binary']\n",
    "# }\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "\n",
    "#         # 'bagging_fraction': (0.5, 0.8),\n",
    "#         # 'bagging_frequency': (5, 8),\n",
    "#         'n_jobs': [-1]\n",
    "#         'feature_fraction': (0.5, 0.8),\n",
    "#         'max_depth': (10, 13),\n",
    "#         'min_data_in_leaf': (90, 120),\n",
    "#         'num_leaves': (1200, 1550)\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find The Best Model We Can\n",
    "\n",
    "The RandomizedSearchCV function will try all our combinations above and select the most accurate model.  \n",
    "\n",
    "That best model is found in the best_estimator_ property of the RandomizedSerachCV object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LGBMClassifier()\n",
    "rs = RandomizedSearchCV(predictor, lgbm_param_grid, cv=5, scoring='f1', n_jobs=-1, n_iter=100, verbose=1)\n",
    "rs.fit(X_train, y_train)\n",
    "evaluate(rs.best_estimator_, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Our Model Further\n",
    "\n",
    "Now we are going to shuffle the data over and over and apply our new model to the results to further determine if we want to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with kfold\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(rs.best_estimator_, X, y, cv=kfold, n_jobs=-1)\n",
    "print(\"Results: %.2f (%.2f) accuracy\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model For Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "with open(f'lgbm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(rs.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm File\n",
    "\n",
    "Make sure the operating system you are NOT using is commented out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows\n",
    "# ! dir best_xgb*\n",
    "! dir lgbm_model*\n",
    "# mac / linux / Unix\n",
    "# ! ls -a best_xgb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
