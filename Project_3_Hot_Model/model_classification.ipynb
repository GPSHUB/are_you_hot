{
 "cells": [
  {
   "source": [
    "# Hot Project Machine Learning Model\n",
    "\n",
    "###  This model reflects manual process for comming up witn an effective model for a classificaiton Project\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies needed to build our model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3 \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm"
   ]
  },
  {
   "source": [
    "## EVALUATE FUNCTION\n",
    "\n",
    "Since we will be trying lots of different models, we built a single function that will evaluate all our models and provide a standardized reporting format.\n",
    "\n",
    "This will allow us to easily pick out the best model we want to move forward with.\n",
    "\n",
    "This function takes in a model ( pipeline ) and our train test split data. From there it simply performes predictions and generates results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Evaluate a pipeline on training and test datasets\n",
    "    '''    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_train_hat = pipeline.predict(X_train)\n",
    "    y_test_hat = pipeline.predict(X_test)\n",
    "    train_f1 = f1_score(y_train_hat, y_train)\n",
    "    train_acc = accuracy_score(y_train_hat, y_train)\n",
    "    test_f1 = f1_score(y_test_hat, y_test)\n",
    "    test_acc = accuracy_score(y_test_hat, y_test)\n",
    "\n",
    "    print(f\"========== Predictor: {type(pipeline).__name__} ==========\")\n",
    "    print(f\"Training result: f1: {train_f1:.3f}, acc: {train_acc:.3f}\")\n",
    "    print(f\"Test result: f1: {test_f1:.3f}, acc: {test_acc:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "source": [
    "## DATA\n",
    "In this case we are reading in top 200 hot and not hot people data.  With this data we are trying to predict if an individual is hot or not based on specific features.\n",
    "\n",
    "#### The features are:\n",
    "- Sex  ->   Male or Female.\n",
    "- Age -> How old is an indiviual.\n",
    "- Eye Color -> Variation of eyes colors.\n",
    "- Hair Color -> Different hair colors effect looks.\n",
    "- Distinctive Features -> Mainly related to how an individual look like.\n",
    "- Height -> How tall are they.\n",
    "- Weight -> Body mass effect looks.\n",
    "- Zodiac Sign -> Is your star lucky.\n",
    "- Tattoo Body Art -> Do they have any inks in their body."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Name     Sex         DOB  Birth Year       Eye Color Hair Color  \\\n",
       "0   Angelina Jolie  Female  06/04/1975        1975            Gray     Blonde   \n",
       "1      Johnny Depp    Male  06/09/1963        1963           Brown      Brown   \n",
       "2  Charlize Theron  Female  08/07/1975        1975           Green      Brown   \n",
       "3        Brad Pitt    Male  12/18/1963        1963            Blue     Blonde   \n",
       "4      Amber Heard  Female  04/22/1986        1986            Blue     Blonde   \n",
       "5       Jared Leto    Male  12/26/1971        1971            Blue      Brown   \n",
       "6  Natalie Portman  Female  06/09/1981        1981           Hazel      Brown   \n",
       "7   Channing Tatum    Male  04/26/1980        1980           Green      Brown   \n",
       "8       Mila Kunis  Female  08/14/1983        1983  Green and Blue      Brown   \n",
       "9  Chris Hemsworth    Male  08/11/1983        1983            Blue     Blonde   \n",
       "\n",
       "  Distinctive Features  Height(ft)  Weight(lbs)  Zodiac Sign Tattoo Body Art  \\\n",
       "0                 Lips        5.50        119.0       Gemini             Yes   \n",
       "1           Cheekbones        5.83        171.0       Gemini             Yes   \n",
       "2           Attractive        5.75        121.0          Leo             Yes   \n",
       "3                  Jaw        5.91        172.0  Sagittarius             Yes   \n",
       "4                 Body        5.58        137.0       Taurus             Yes   \n",
       "5                 Eyes        5.75        152.0    Capricorn             Yes   \n",
       "6                Moles        5.25        110.0       Gemini              No   \n",
       "7                 Eyes        6.08        196.0       Taurus             Yes   \n",
       "8                 Body        5.33        115.0          Leo              No   \n",
       "9                Voice        6.25        201.0          Leo             Yes   \n",
       "\n",
       "   Hot Test  Ht/Wt Ratio  Age  \n",
       "0         0        21.64   45  \n",
       "1         0        29.33   57  \n",
       "2         0        21.04   45  \n",
       "3         0        29.10   57  \n",
       "4         0        24.55   34  \n",
       "5         0        26.43   49  \n",
       "6         0        20.95   39  \n",
       "7         0        32.24   40  \n",
       "8         0        21.58   37  \n",
       "9         0        32.16   37  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>DOB</th>\n      <th>Birth Year</th>\n      <th>Eye Color</th>\n      <th>Hair Color</th>\n      <th>Distinctive Features</th>\n      <th>Height(ft)</th>\n      <th>Weight(lbs)</th>\n      <th>Zodiac Sign</th>\n      <th>Tattoo Body Art</th>\n      <th>Hot Test</th>\n      <th>Ht/Wt Ratio</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Angelina Jolie</td>\n      <td>Female</td>\n      <td>06/04/1975</td>\n      <td>1975</td>\n      <td>Gray</td>\n      <td>Blonde</td>\n      <td>Lips</td>\n      <td>5.50</td>\n      <td>119.0</td>\n      <td>Gemini</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>21.64</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Johnny Depp</td>\n      <td>Male</td>\n      <td>06/09/1963</td>\n      <td>1963</td>\n      <td>Brown</td>\n      <td>Brown</td>\n      <td>Cheekbones</td>\n      <td>5.83</td>\n      <td>171.0</td>\n      <td>Gemini</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>29.33</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Charlize Theron</td>\n      <td>Female</td>\n      <td>08/07/1975</td>\n      <td>1975</td>\n      <td>Green</td>\n      <td>Brown</td>\n      <td>Attractive</td>\n      <td>5.75</td>\n      <td>121.0</td>\n      <td>Leo</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>21.04</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Brad Pitt</td>\n      <td>Male</td>\n      <td>12/18/1963</td>\n      <td>1963</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Jaw</td>\n      <td>5.91</td>\n      <td>172.0</td>\n      <td>Sagittarius</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>29.10</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Amber Heard</td>\n      <td>Female</td>\n      <td>04/22/1986</td>\n      <td>1986</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Body</td>\n      <td>5.58</td>\n      <td>137.0</td>\n      <td>Taurus</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>24.55</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jared Leto</td>\n      <td>Male</td>\n      <td>12/26/1971</td>\n      <td>1971</td>\n      <td>Blue</td>\n      <td>Brown</td>\n      <td>Eyes</td>\n      <td>5.75</td>\n      <td>152.0</td>\n      <td>Capricorn</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>26.43</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Natalie Portman</td>\n      <td>Female</td>\n      <td>06/09/1981</td>\n      <td>1981</td>\n      <td>Hazel</td>\n      <td>Brown</td>\n      <td>Moles</td>\n      <td>5.25</td>\n      <td>110.0</td>\n      <td>Gemini</td>\n      <td>No</td>\n      <td>0</td>\n      <td>20.95</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Channing Tatum</td>\n      <td>Male</td>\n      <td>04/26/1980</td>\n      <td>1980</td>\n      <td>Green</td>\n      <td>Brown</td>\n      <td>Eyes</td>\n      <td>6.08</td>\n      <td>196.0</td>\n      <td>Taurus</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>32.24</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Mila Kunis</td>\n      <td>Female</td>\n      <td>08/14/1983</td>\n      <td>1983</td>\n      <td>Green and Blue</td>\n      <td>Brown</td>\n      <td>Body</td>\n      <td>5.33</td>\n      <td>115.0</td>\n      <td>Leo</td>\n      <td>No</td>\n      <td>0</td>\n      <td>21.58</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Chris Hemsworth</td>\n      <td>Male</td>\n      <td>08/11/1983</td>\n      <td>1983</td>\n      <td>Blue</td>\n      <td>Blonde</td>\n      <td>Voice</td>\n      <td>6.25</td>\n      <td>201.0</td>\n      <td>Leo</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>32.16</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# load dataset from sqlite dataBase. Creat an engine and then use pandas to read and convert the sql table into dataframe\n",
    "\n",
    "engine = create_engine('sqlite:///../dataBase/Are_You_Hot.db')\n",
    "hot_df = pd.read_sql('select * from hot', engine)\n",
    "hot_df.head(10)"
   ]
  },
  {
   "source": [
    "## DataFrame cleanup "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Sex Eye Color Hair Color Distinctive Features  Zodiac Sign  \\\n",
       "196    Male     Brown      Brown                Smile  Sagittarius   \n",
       "197    Male     Black       Bald                 Face       Cancer   \n",
       "198    Male     Brown      Brown                 Hair  Sagittarius   \n",
       "199  Female     Black      Black                Smile       Cancer   \n",
       "200    Male      Blue      Brown                 Hair       Cancer   \n",
       "\n",
       "    Tattoo Body Art  Hot Test  Ht/Wt Ratio  Age  \n",
       "196              No         1        36.38   68  \n",
       "197              No         1        32.48   57  \n",
       "198             Yes         1        30.00   55  \n",
       "199              No         1        57.09   37  \n",
       "200              No         1        27.65   38  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Eye Color</th>\n      <th>Hair Color</th>\n      <th>Distinctive Features</th>\n      <th>Zodiac Sign</th>\n      <th>Tattoo Body Art</th>\n      <th>Hot Test</th>\n      <th>Ht/Wt Ratio</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>196</th>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>Brown</td>\n      <td>Smile</td>\n      <td>Sagittarius</td>\n      <td>No</td>\n      <td>1</td>\n      <td>36.38</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Male</td>\n      <td>Black</td>\n      <td>Bald</td>\n      <td>Face</td>\n      <td>Cancer</td>\n      <td>No</td>\n      <td>1</td>\n      <td>32.48</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>Brown</td>\n      <td>Hair</td>\n      <td>Sagittarius</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>30.00</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>Female</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>Smile</td>\n      <td>Cancer</td>\n      <td>No</td>\n      <td>1</td>\n      <td>57.09</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>Male</td>\n      <td>Blue</td>\n      <td>Brown</td>\n      <td>Hair</td>\n      <td>Cancer</td>\n      <td>No</td>\n      <td>1</td>\n      <td>27.65</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Data clean up and droping columns we are not going to use to train our model.\n",
    "\n",
    "clean_df = hot_df.drop(['Name', 'DOB', 'Birth Year', 'Height(ft)', 'Weight(lbs)'], axis=1)\n",
    "clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 201 entries, 0 to 200\nData columns (total 57 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   Sex_Male                         201 non-null    uint8  \n 1   Eye Color_Blue                   201 non-null    uint8  \n 2   Eye Color_Brown                  201 non-null    uint8  \n 3   Eye Color_Gray                   201 non-null    uint8  \n 4   Eye Color_Green                  201 non-null    uint8  \n 5   Eye Color_Green and Blue         201 non-null    uint8  \n 6   Eye Color_Hazel                  201 non-null    uint8  \n 7   Hair Color_Bald                  201 non-null    uint8  \n 8   Hair Color_Black                 201 non-null    uint8  \n 9   Hair Color_Blonde                201 non-null    uint8  \n 10  Hair Color_Brown                 201 non-null    uint8  \n 11  Hair Color_Brunette              201 non-null    uint8  \n 12  Hair Color_Gray                  201 non-null    uint8  \n 13  Hair Color_Red                   201 non-null    uint8  \n 14  Hair Color_White                 201 non-null    uint8  \n 15  Distinctive Features_Bald        201 non-null    uint8  \n 16  Distinctive Features_Body        201 non-null    uint8  \n 17  Distinctive Features_Cheekbones  201 non-null    uint8  \n 18  Distinctive Features_Cheeks      201 non-null    uint8  \n 19  Distinctive Features_Chin        201 non-null    uint8  \n 20  Distinctive Features_Ears        201 non-null    uint8  \n 21  Distinctive Features_Eyebrows    201 non-null    uint8  \n 22  Distinctive Features_Eyes        201 non-null    uint8  \n 23  Distinctive Features_Face        201 non-null    uint8  \n 24  Distinctive Features_Forehead    201 non-null    uint8  \n 25  Distinctive Features_Goatee      201 non-null    uint8  \n 26  Distinctive Features_Hair        201 non-null    uint8  \n 27  Distinctive Features_Height      201 non-null    uint8  \n 28  Distinctive Features_Jaw         201 non-null    uint8  \n 29  Distinctive Features_Jawline     201 non-null    uint8  \n 30  Distinctive Features_Legs        201 non-null    uint8  \n 31  Distinctive Features_Lips        201 non-null    uint8  \n 32  Distinctive Features_Moles       201 non-null    uint8  \n 33  Distinctive Features_Muscular    201 non-null    uint8  \n 34  Distinctive Features_Nose        201 non-null    uint8  \n 35  Distinctive Features_Skin        201 non-null    uint8  \n 36  Distinctive Features_Smile       201 non-null    uint8  \n 37  Distinctive Features_Stubble     201 non-null    uint8  \n 38  Distinctive Features_Style       201 non-null    uint8  \n 39  Distinctive Features_Teeth       201 non-null    uint8  \n 40  Distinctive Features_Voice       201 non-null    uint8  \n 41  Zodiac Sign_Aquarius             201 non-null    uint8  \n 42  Zodiac Sign_Aries                201 non-null    uint8  \n 43  Zodiac Sign_Cancer               201 non-null    uint8  \n 44  Zodiac Sign_Capricorn            201 non-null    uint8  \n 45  Zodiac Sign_Gemini               201 non-null    uint8  \n 46  Zodiac Sign_Leo                  201 non-null    uint8  \n 47  Zodiac Sign_Libra                201 non-null    uint8  \n 48  Zodiac Sign_Pisces               201 non-null    uint8  \n 49  Zodiac Sign_Sagittarius          201 non-null    uint8  \n 50  Zodiac Sign_Scorpio              201 non-null    uint8  \n 51  Zodiac Sign_Taurus               201 non-null    uint8  \n 52  Zodiac Sign_Virgo                201 non-null    uint8  \n 53  Tattoo Body Art_Yes              201 non-null    uint8  \n 54  Hot Test                         201 non-null    int64  \n 55  Ht/Wt Ratio                      201 non-null    float64\n 56  Age                              201 non-null    int64  \ndtypes: float64(1), int64(2), uint8(54)\nmemory usage: 15.4 KB\n"
     ]
    }
   ],
   "source": [
    "# We need to convert any string/object column to integer for training our model\n",
    "# We decided to use dummies modeule to do our labeling \n",
    "\n",
    "cat_col = clean_df.select_dtypes(include=['object']).columns\n",
    "dummies = pd.get_dummies(clean_df[cat_col],drop_first=True)\n",
    "without_dummies = clean_df.drop(cat_col,axis=1)\n",
    "clean_data = pd.concat([dummies,without_dummies],axis=1)\n",
    "clean_data.info()"
   ]
  },
  {
   "source": [
    "## Extract Features from Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sex_Male                           0\n",
       "Eye Color_Blue                     0\n",
       "Eye Color_Brown                    0\n",
       "Eye Color_Gray                     0\n",
       "Eye Color_Green                    0\n",
       "Eye Color_Green and Blue           0\n",
       "Eye Color_Hazel                    0\n",
       "Hair Color_Bald                    0\n",
       "Hair Color_Black                   0\n",
       "Hair Color_Blonde                  0\n",
       "Hair Color_Brown                   0\n",
       "Hair Color_Brunette                0\n",
       "Hair Color_Gray                    0\n",
       "Hair Color_Red                     0\n",
       "Hair Color_White                   0\n",
       "Distinctive Features_Bald          0\n",
       "Distinctive Features_Body          0\n",
       "Distinctive Features_Cheekbones    0\n",
       "Distinctive Features_Cheeks        0\n",
       "Distinctive Features_Chin          0\n",
       "Distinctive Features_Ears          0\n",
       "Distinctive Features_Eyebrows      0\n",
       "Distinctive Features_Eyes          0\n",
       "Distinctive Features_Face          0\n",
       "Distinctive Features_Forehead      0\n",
       "Distinctive Features_Goatee        0\n",
       "Distinctive Features_Hair          0\n",
       "Distinctive Features_Height        0\n",
       "Distinctive Features_Jaw           0\n",
       "Distinctive Features_Jawline       0\n",
       "Distinctive Features_Legs          0\n",
       "Distinctive Features_Lips          0\n",
       "Distinctive Features_Moles         0\n",
       "Distinctive Features_Muscular      0\n",
       "Distinctive Features_Nose          0\n",
       "Distinctive Features_Skin          0\n",
       "Distinctive Features_Smile         0\n",
       "Distinctive Features_Stubble       0\n",
       "Distinctive Features_Style         0\n",
       "Distinctive Features_Teeth         0\n",
       "Distinctive Features_Voice         0\n",
       "Zodiac Sign_Aquarius               0\n",
       "Zodiac Sign_Aries                  0\n",
       "Zodiac Sign_Cancer                 0\n",
       "Zodiac Sign_Capricorn              0\n",
       "Zodiac Sign_Gemini                 0\n",
       "Zodiac Sign_Leo                    0\n",
       "Zodiac Sign_Libra                  0\n",
       "Zodiac Sign_Pisces                 0\n",
       "Zodiac Sign_Sagittarius            0\n",
       "Zodiac Sign_Scorpio                0\n",
       "Zodiac Sign_Taurus                 0\n",
       "Zodiac Sign_Virgo                  0\n",
       "Tattoo Body Art_Yes                0\n",
       "Hot Test                           0\n",
       "Ht/Wt Ratio                        0\n",
       "Age                                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# make sure there is no nan\n",
    "# if there is nan, we need to deal with it, either by imputing or discarding\n",
    "clean_data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "The stratify argument is used to make sure the train test split data has similar populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our X and y values for model training and test\n",
    "\n",
    "X = clean_data.drop('Hot Test', axis=1).values \n",
    "y = hot_df['Hot Test'].values.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick A Model For A Base Point To Evaluate Other Models Against\n",
    "\n",
    "In this case we are choosing Logistric Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========== Predictor: Pipeline ==========\nTraining result: f1: 0.870, acc: 0.869\nTest result: f1: 0.718, acc: 0.732\n\n"
     ]
    }
   ],
   "source": [
    "# Do LogisticRegression first to establish a baseline performance\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()), # scale first before feeding data into lgr\n",
    "    ('lgr', LogisticRegression()),\n",
    "])\n",
    "evaluate(pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "source": [
    "## Try A Few More Models..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[23:44:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "========== Predictor: XGBClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.732, acc: 0.732\n",
      "\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.879, acc: 0.881\n",
      "Test result: f1: 0.791, acc: 0.780\n",
      "\n",
      "========== Predictor: RandomForestClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.744, acc: 0.732\n",
      "\n",
      "========== Predictor: DecisionTreeClassifier ==========\n",
      "Training result: f1: 1.000, acc: 1.000\n",
      "Test result: f1: 0.615, acc: 0.634\n",
      "\n",
      "========== Predictor: GradientBoostingClassifier ==========\n",
      "Training result: f1: 0.981, acc: 0.981\n",
      "Test result: f1: 0.762, acc: 0.756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try other predictors\n",
    "\n",
    "evaluate(XGBClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(LGBMClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)\n",
    "evaluate(GradientBoostingClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "source": [
    "## Let's Pick a Final Model To Move Forward With\n",
    "\n",
    "From the above evaluations, it looks like LGBMClassifier is a very promising candidate\n",
    "\n",
    "We will then hypertune the classifier model to come up with the best model we can."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Create Our Tuning Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV on LGBM\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 300, 400],\n",
    "    'max_depth': np.arange(5, 20),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.05),\n",
    "    'min_child_weight': np.arange(1, 10),\n",
    "    'colsample_bytree': np.arange(0.2, 1.0, 0.1),\n",
    "    'gamma': [0, 0.001, 0.002, 0.003, 0.004, 0.005, 1e-2],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "#     'learning_rate': [ 0.1],\n",
    "#     'num_leaves': [31],\n",
    "#     'boosting_type' : ['gbdt'],\n",
    "#     'objective' : ['binary']\n",
    "# }\n",
    "\n",
    "# lgbm_param_grid = {\n",
    "\n",
    "#         # 'bagging_fraction': (0.5, 0.8),\n",
    "#         # 'bagging_frequency': (5, 8),\n",
    "#         'n_jobs': [-1]\n",
    "#         'feature_fraction': (0.5, 0.8),\n",
    "#         'max_depth': (10, 13),\n",
    "#         'min_data_in_leaf': (90, 120),\n",
    "#         'num_leaves': (1200, 1550)\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find The Best Model We Can\n",
    "\n",
    "The RandomizedSearchCV function will try all our combinations above and select the most accurate model.  \n",
    "\n",
    "That best model is found in the best_estimator_ property of the RandomizedSerachCV object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.812, acc: 0.806\n",
      "Test result: f1: 0.750, acc: 0.756\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "predictor = LGBMClassifier()\n",
    "rs = RandomizedSearchCV(predictor, lgbm_param_grid, cv=5, scoring='f1', n_jobs=-1, n_iter=100, verbose=1)\n",
    "rs.fit(X_train, y_train)\n",
    "evaluate(rs.best_estimator_, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Our Model Further\n",
    "\n",
    "Now we are going to shuffle the data over and over and apply our new model to the results to further determine if we want to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results: 0.56 (0.12) accuracy\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with kfold\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(rs.best_estimator_, X, y, cv=kfold, n_jobs=-1)\n",
    "print(\"Results: %.2f (%.2f) accuracy\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model For Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "with open(f'lgbm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(rs.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm File\n",
    "\n",
    "Make sure the operating system you are NOT using is commented out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Volume in drive C is TI10653400C\n Volume Serial Number is 24D7-5A9C\n\n Directory of c:\\Users\\tahir\\Desktop\\repos\\are_you_hot\\Project_3_Hot_Model\n\n12/13/2020  12:09 AM            12,780 lgbm_model.pickle\n               1 File(s)         12,780 bytes\n               0 Dir(s)  34,847,309,824 bytes free\n"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "# ! dir best_xgb*\n",
    "! dir lgbm_model*\n",
    "# mac / linux / Unix\n",
    "# ! ls -a best_xgb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('PythonAdv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6de8536eaa4070947253de6ee6fc4b8f7fe35d929fbfb620a9bfbc52619c5b86"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}