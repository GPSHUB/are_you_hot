{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Machine Learning Example\n",
    "\n",
    "###  This example reflects what a simple manual process for coming up witn an effective model for a classificaiton problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE FUNCTION\n",
    "\n",
    "Since we will be trying lots of different models, it would be nice to have a single function that will evaluate all our models and provide a standardized reporting format.\n",
    "\n",
    "This will allow us to easily pick out the model we want to move forward with.\n",
    "\n",
    "This function takes in a model ( pipeline ) and our train test split data. From there it simply performes predictions and generates results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Evaluate a pipeline on training and test datasets\n",
    "    '''    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_train_hat = pipeline.predict(X_train)\n",
    "    y_test_hat = pipeline.predict(X_test)\n",
    "    train_f1 = f1_score(y_train_hat, y_train)\n",
    "    train_acc = accuracy_score(y_train_hat, y_train)\n",
    "    test_f1 = f1_score(y_test_hat, y_test)\n",
    "    test_acc = accuracy_score(y_test_hat, y_test)\n",
    "\n",
    "    print(f\"========== Predictor: {type(pipeline).__name__} ==========\")\n",
    "    print(f\"Training result: f1: {train_f1:.3f}, acc: {train_acc:.3f}\")\n",
    "    print(f\"Test result: f1: {test_f1:.3f}, acc: {test_acc:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA\n",
    "\n",
    "In this case we are reading in transfusion data.  With this data we are trying to predict in an individual has given blood on Marth 2007 based on specific features.\n",
    "\n",
    "#### The features are:\n",
    "- Recency  ->   How long since the individual last gave blood\n",
    "- Frequency -> How many times has the indivuaul give blood\n",
    "- Monetary -> Amount of usable blood given\n",
    "- Time -> How many months have they been given blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Year</th>\n",
       "      <th>Eye Color</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Distinctive Features</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Zodiac Sign</th>\n",
       "      <th>Tattoo Body Art</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jamie Dornan</td>\n",
       "      <td>Male</td>\n",
       "      <td>5/1/1982</td>\n",
       "      <td>1982</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>6.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Keira Knightley</td>\n",
       "      <td>Female</td>\n",
       "      <td>3/26/1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>5.7</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Aries</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chris Evans</td>\n",
       "      <td>Male</td>\n",
       "      <td>6/13/1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Muscular</td>\n",
       "      <td>6.0</td>\n",
       "      <td>176.5</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Name     Sex        DOB  Year Eye Color Hair Color  \\\n",
       "0           0     Jamie Dornan    Male   5/1/1982  1982      Blue      Brown   \n",
       "1           1  Keira Knightley  Female  3/26/1985  1985     Brown      Brown   \n",
       "2           2      Chris Evans    Male  6/13/1981  1981      Blue      Brown   \n",
       "\n",
       "  Distinctive Features  Height  Weight Zodiac Sign Tattoo Body Art  \n",
       "0                 Eyes     6.0   170.0      Taurus              No  \n",
       "1                 Eyes     5.7   119.0       Aries              No  \n",
       "2             Muscular     6.0   176.5      Gemini             Yes  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(\"giam_celebs.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2e5efb3b9b0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# build X and y matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\envs\\pythondata\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tc'"
     ]
    }
   ],
   "source": [
    "# build X and y matrices\n",
    "X = df.Year.values.reshape(-1, 1)\n",
    "y = df.Weight.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "Name                    0\n",
       "Sex                     0\n",
       "DOB                     0\n",
       "Birth Year              0\n",
       "Eye Color               0\n",
       "Hair Color              0\n",
       "Distinctive Features    0\n",
       "Height(ft)              0\n",
       "Weight(lbs)             0\n",
       "Zodiac Sign             0\n",
       "Tattoo Body Art         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preliminary Data Analysis\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "The stratify argument is used to make sure the train test split data has similar populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick A Model For A Base Point To Evaluate Other Models Against\n",
    "\n",
    "In this case we are choosing Logistric Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Predictor: Pipeline ==========\n",
      "Training result: f1: 0.201, acc: 0.774\n",
      "Test result: f1: 0.186, acc: 0.767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try LogisticRegression to establish a baseline performance\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()), # remember to scale first before feeding data into lgr\n",
    "    ('lgr', LogisticRegression()),\n",
    "])\n",
    "evaluate(pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's Try A Few More..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Predictor: XGBClassifier ==========\n",
      "Training result: f1: 0.798, acc: 0.916\n",
      "Test result: f1: 0.471, acc: 0.760\n",
      "\n",
      "========== Predictor: LGBMClassifier ==========\n",
      "Training result: f1: 0.672, acc: 0.871\n",
      "Test result: f1: 0.464, acc: 0.753\n",
      "\n",
      "========== Predictor: RandomForestClassifier ==========\n",
      "Training result: f1: 0.855, acc: 0.938\n",
      "Test result: f1: 0.394, acc: 0.733\n",
      "\n",
      "========== Predictor: GradientBoostingClassifier ==========\n",
      "Training result: f1: 0.597, acc: 0.851\n",
      "Test result: f1: 0.467, acc: 0.787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try other predictors\n",
    "evaluate(XGBClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(LGBMClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(RandomForestClassifier(n_jobs=-1), X_train, X_test, y_train, y_test)\n",
    "evaluate(GradientBoostingClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Pick a Final Model To Move Forward With\n",
    "\n",
    "From the above evaluations, it looks like XGBClassifier is a very promising candidate\n",
    "\n",
    "We will then hypertune the classifier model to come up with the best model we can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Create Our Tuning Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV on XGB\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 300, 400],\n",
    "    'max_depth': np.arange(5, 20),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.05),\n",
    "    'min_child_weight': np.arange(1, 10),\n",
    "    'colsample_bytree': np.arange(0.2, 1.0, 0.1),\n",
    "    'gamma': [0, 0.001, 0.002, 0.003, 0.004, 0.005, 1e-2],\n",
    "    'n_jobs': [-1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find The Best Model We Can\n",
    "\n",
    "The RandomizedSearchCV function will try all our combinations above and select the most accurate model.  \n",
    "\n",
    "That best model is found in the best_estimator_ property of the RandomizedSerachCV object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Predictor: XGBClassifier ==========\n",
      "Training result: f1: 0.667, acc: 0.868\n",
      "Test result: f1: 0.478, acc: 0.767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = XGBClassifier()\n",
    "rs = RandomizedSearchCV(predictor, xgb_param_grid, cv=5, scoring='f1', n_jobs=-1, n_iter=100, verbose=1)\n",
    "rs.fit(X_train, y_train)\n",
    "evaluate(rs.best_estimator_, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Our Model Further\n",
    "\n",
    "Now we are going to shuffle the data over and over and apply our new model to the results to further determine if we want to use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 0.77 (0.12) accuracy\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with kfold\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(rs.best_estimator_, X, y, cv=kfold, n_jobs=-1)\n",
    "print(\"Results: %.2f (%.2f) accuracy\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model For Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(f'best_xgb_model.pickle', 'wb') as f:\n",
    "    pickle.dump(rs.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm File\n",
    "\n",
    "Make sure the operating system you are NOT using is commented out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 5075-944D\n",
      "\n",
      " Directory of C:\\Users\\GPS\\Desktop\\Im your CLONE!!!\\extra_ml_stuff\\00_Project_3_Type_Example\n",
      "\n",
      "12/01/2020  11:29 AM           292,714 best_xgb_model.pickle\n",
      "               1 File(s)        292,714 bytes\n",
      "               0 Dir(s)  115,740,356,608 bytes free\n"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "! dir best_xgb*\n",
    "# mac / linux / Unix\n",
    "# ! ls -a best_xgb*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
